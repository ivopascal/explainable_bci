# explainable_bci
A repo where we attempt to apply XAI methods to see where an EEG classifier is looking. This can indicate whether the understanding of the CNN is cognitively plausible.

This is applied to Error Related Potentials classification, where the explanations are generated with SHAP.
